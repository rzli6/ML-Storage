{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from importlib import reload\n",
    "import find_cpt\n",
    "from rgf.sklearn import RGFClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold, cross_val_score, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "data_dir = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_stat(model, X, y):\n",
    "    f_score = np.average(cross_val_score(model, X, y, cv=5, scoring='f1', n_jobs=-1))\n",
    "    r_score = np.average(cross_val_score(model, X, y, cv=5, scoring='recall', n_jobs=-1))\n",
    "    p_score = np.average(cross_val_score(model, X, y, cv=5, scoring='precision', n_jobs=-1))\n",
    "    print(f_score)\n",
    "    print(r_score)\n",
    "    print(p_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize = pd.read_csv('./preprocess/summarize.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4412267, 53)\n",
      "114\n",
      "0.011396581025692293\n"
     ]
    }
   ],
   "source": [
    "# Transfer learning!\n",
    "test = pd.read_csv('./data/2017-01-01.csv')\n",
    "SgtB_features = list(test.loc[test['model'] == 'ST8000DM002'].dropna(axis=1, how='all').columns.values)\n",
    "def process_SgtB(df, name):\n",
    "    df = df.loc[df['model'] == name]\n",
    "    return df[SgtB_features]\n",
    "type_dict = {feature: np.float32 for feature in SgtB_features[5:]}\n",
    "SgtB = pd.concat([process_SgtB(pd.read_csv(os.path.join('./data/', filename), dtype=type_dict), 'ST8000DM002') for filename in os.listdir(data_dir)])\n",
    "print(SgtB.shape)\n",
    "\n",
    "# get fail name in B\n",
    "fail_names_SgtB = SgtB.loc[SgtB['failure'] == 1]['serial_number'].unique()\n",
    "print(fail_names_SgtB.size)\n",
    "print(fail_names_SgtB.size / SgtB['serial_number'].unique().size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date', 'serial_number', 'model', 'capacity_bytes', 'failure', 'smart_1_normalized', 'smart_1_raw', 'smart_3_normalized', 'smart_3_raw', 'smart_4_normalized', 'smart_4_raw', 'smart_5_normalized', 'smart_5_raw', 'smart_7_normalized', 'smart_7_raw', 'smart_9_normalized', 'smart_9_raw', 'smart_10_normalized', 'smart_10_raw', 'smart_12_normalized', 'smart_12_raw', 'smart_184_normalized', 'smart_184_raw', 'smart_187_normalized', 'smart_187_raw', 'smart_188_normalized', 'smart_188_raw', 'smart_189_normalized', 'smart_189_raw', 'smart_190_normalized', 'smart_190_raw', 'smart_191_normalized', 'smart_191_raw', 'smart_192_normalized', 'smart_192_raw', 'smart_193_normalized', 'smart_193_raw', 'smart_194_normalized', 'smart_194_raw', 'smart_195_normalized', 'smart_195_raw', 'smart_197_normalized', 'smart_197_raw', 'smart_198_normalized', 'smart_198_raw', 'smart_199_normalized', 'smart_199_raw', 'smart_240_normalized', 'smart_240_raw', 'smart_241_normalized', 'smart_241_raw', 'smart_242_normalized', 'smart_242_raw']\n"
     ]
    }
   ],
   "source": [
    "print(SgtB_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1236\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('./data/2017-01-01.csv')\n",
    "SgtA_features = list(test.loc[test['model'] == 'ST4000DM000'].dropna(axis=1, how='all').columns.values)\n",
    "def process_SgtA(df, name):\n",
    "    df = df.loc[df['model'] == name]\n",
    "    return df[SgtA_features]\n",
    "type_dict = {feature: np.float32 for feature in SgtA_features[5:]}\n",
    "SgtA = pd.concat([process_SgtA(pd.read_csv(os.path.join(data_dir, filename), dtype=type_dict), 'ST4000DM000') for filename in os.listdir(data_dir)])\n",
    "fail_names_SgtA = SgtA.loc[SgtA['failure'] == 1]['serial_number'].unique()\n",
    "print(fail_names_SgtA.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "# prepare features\n",
    "features_percent = summarize.T[0].iloc[1:]\n",
    "selected_features = features_percent[features_percent > 0.01].sort_values(ascending=False)\n",
    "# print(selected_features)\n",
    "\n",
    "TR_selected_features = [i for i in selected_features.index.values if i in SgtB_features]\n",
    "print(TR_selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ray\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35209, 32)\n"
     ]
    }
   ],
   "source": [
    "compacted_info_SgtA = pd.read_csv('./preprocess/compacted.csv')\n",
    "compacted_SgtA = compacted_info_SgtA[TR_selected_features]\n",
    "compacted_SgtA['serial_number'] = compacted_info_SgtA['serial_number']\n",
    "compacted_SgtA.to_csv('./preprocess/TR_compacted_SgtA.csv')\n",
    "print(compacted_SgtA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ray\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: pd.ewm_mean is deprecated for ndarrays and will be removed in a future version\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'compacted_SgtB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-09dfbf00e7ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mcompacted_info_SgtB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSgtB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'serial_number'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunctions_group2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mcompacted_info_SgtB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./preprocess/TR_compacted_SgtB.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompacted_SgtB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'compacted_SgtB' is not defined"
     ]
    }
   ],
   "source": [
    "# Compact info\n",
    "def get_cmpt_info_SgtB(data):\n",
    "    return pd.ewma(data.values, span=np.round(summarize.iloc[1][data.name]))[-1]\n",
    "functions_group2 = {n: get_cmpt_info_SgtB for n in TR_selected_features}\n",
    "# print(functions_group1)\n",
    "compacted_SgtB = SgtB.groupby('serial_number', as_index=False).agg(functions_group2)\n",
    "compacted_SgtB.to_csv('./preprocess/TR_compacted_SgtB.csv')\n",
    "print(compacted_SgtB.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10003, 32)\n",
      "(35209, 32)\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "print(compacted_SgtB.shape)\n",
    "print(compacted_SgtA.shape)\n",
    "print(len(TR_selected_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare model\n",
    "TR_X_health = compacted_SgtA.loc[~compacted_SgtA['serial_number'].isin(fail_names_SgtA)].drop('serial_number', axis=1).values\n",
    "kmeans = KMeans(n_clusters=150, random_state=0, n_jobs=-1).fit(TR_X_health)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2736, 31)\n",
      "(2736,)\n"
     ]
    }
   ],
   "source": [
    "TR_X_health_transformed = np.concatenate([TR_X_health[np.argsort(kmeans.transform(TR_X_health)[:, j])[::-1][:10]] for j in range(0, 150)], axis=0)\n",
    "TR_X_failed = compacted_SgtA.loc[compacted_SgtA['serial_number'].isin(fail_names_SgtA)].drop('serial_number', axis=1).values\n",
    "TR_X_failed.shape\n",
    "TR_X_train = np.concatenate((TR_X_health_transformed, TR_X_failed), axis=0)\n",
    "TR_y_train = np.concatenate((np.zeros(TR_X_health_transformed.shape[0]), np.ones(TR_X_failed.shape[0])), axis=0) \n",
    "print(TR_X_train.shape)\n",
    "print(TR_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    3.4s remaining:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9888837173463948\n",
      "0.9910963823951938\n",
      "0.9871212121212121\n"
     ]
    }
   ],
   "source": [
    "# tune RGF\n",
    "search_grid = {\n",
    "    'max_leaf': [1000],\n",
    "    'algorithm': ['RGF_Sib'],\n",
    "    'test_interval': [100],\n",
    "    'loss': ['Log']\n",
    "}\n",
    "\n",
    "TR_rgf_model = RGFClassifier()\n",
    "TR_rgf_grid = GridSearchCV(estimator= TR_rgf_model, param_grid=search_grid, \n",
    "    cv=5, scoring='f1', n_jobs=-1, verbose=2)\n",
    "TR_rgf_grid.fit(TR_X_train, TR_y_train)\n",
    "model_stat(TR_rgf_model, TR_X_train, TR_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10003, 31)\n",
      "(10003,)\n",
      "114\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "TR_X_test = compacted_SgtB.drop('serial_number', axis=1).values\n",
    "TR_y_test = np.array([1 if sn in fail_names_SgtB else 0 for sn in compacted_SgtB['serial_number'].values])\n",
    "print(TR_X_test.shape)\n",
    "print(TR_y_test.shape)\n",
    "print(np.sum(TR_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.022347473548897462\n",
      "0.9912280701754386\n",
      "0.011301130113011301\n"
     ]
    }
   ],
   "source": [
    "TR_rgf_model = RGFClassifier(max_leaf=1000, algorithm='RGF_Sib', test_interval=100, loss='Log')\n",
    "TR_rgf_model.fit(TR_X_train, TR_y_train)\n",
    "TR_y_pred = TR_rgf_model.predict(TR_X_test)\n",
    "print(f1_score(TR_y_test, TR_y_pred))\n",
    "print(recall_score(TR_y_test, TR_y_pred))\n",
    "print(precision_score(TR_y_test, TR_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999.0\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(TR_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
