{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from importlib import reload\n",
    "import find_cpt\n",
    "from rgf.sklearn import RGFClassifier, FastRGFClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold, cross_val_score, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "# data_dir = \"./data-2015\"\n",
    "data_dirs = ['./data-2014/', './data-2015/']\n",
    "# model_name = 'ST4000DM000'\n",
    "# model_name = 'ST31500541AS'\n",
    "model_name = 'Hitachi HDS722020ALA330'\n",
    "# model_name = 'Hitachi HDS5C3030ALA630'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./data-2015/2015-01-01.csv')\n",
    "all_features = list(test.loc[test['model'] == model_name].dropna(axis=1, how='all').columns.values)\n",
    "def process_SgtA(df, name):\n",
    "    df = df.loc[df['model'] == name]\n",
    "    return df[all_features]\n",
    "type_dict = {feature: np.float32 for feature in all_features[5:]}\n",
    "SgtA = pd.concat([process_SgtA(pd.read_csv(os.path.join(data_dir, filename), dtype=type_dict), model_name) for data_dir in data_dirs for filename in os.listdir(data_dir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ST4000DM000\n",
      "n_disks: 29908\n",
      "n_failed: 824\n",
      "failed_percent: 0.027551156881102046\n"
     ]
    }
   ],
   "source": [
    "# find names of the failure disk\n",
    "fail_names = SgtA.loc[SgtA['failure'] == 1]['serial_number'].unique()\n",
    "print(model_name)\n",
    "print('n_disks: ' + str(SgtA['serial_number'].unique().size))\n",
    "print('n_failed: ' + str(fail_names.size))\n",
    "print('failed_percent: '  + str(fail_names.size / SgtA['serial_number'].unique().size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hitachi HDS722020ALA330\n",
    "n_disks: 4737\n",
    "n_failed: 159\n",
    "failed_percent: 0.03356554781507283\n",
    "\n",
    "Hitachi HDS5C3030ALA630\n",
    "n_disks: 4634\n",
    "n_failed: 74\n",
    "failed_percent: 0.015968925334484248\n",
    "\n",
    "ST4000DM000\n",
    "n_disks: 29908\n",
    "n_failed: 824\n",
    "failed_percent: 0.027551156881102046\n",
    "\n",
    "ST31500541AS\n",
    "n_disks: 1970\n",
    "n_failed: 271\n",
    "failed_percent: 0.13756345177664975"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find failure disks\n",
    "failure_disk_group = SgtA.loc[SgtA['serial_number'].isin(fail_names)].sort_values('date', ascending=True).groupby('serial_number')\n",
    "\n",
    "def get_cpt(data):\n",
    "    changepoint = find_cpt.cpt(data=data, type='normal-mean').find_changepoint()\n",
    "    if changepoint > 0:\n",
    "        return data.size - changepoint\n",
    "    return changepoint\n",
    "\n",
    "functions_group = {n: get_cpt for n in all_features[5:]}\n",
    "all_cpt_series = failure_disk_group.agg(functions_group)\n",
    "# print(all_cpt_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cpt_series.to_csv('./preprocess/' + model_name + '_cpt.csv')\n",
    "def get_percent(data):\n",
    "    return data[(data>0) & (data <=100)].dropna().size/data.dropna().size\n",
    "def get_median(data):\n",
    "    return data[data>0].dropna().median()\n",
    "def get_mean(data):\n",
    "    return data[data>0].dropna().mean()\n",
    "summarize = all_cpt_series.agg([get_percent, get_median, get_mean])\n",
    "# print(summarize)\n",
    "summarize.to_csv('./preprocess/' + model_name + '_summarize.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smart_193_raw    0.442961\n",
      "smart_197_raw    0.429612\n",
      "smart_198_raw    0.417476\n",
      "smart_194_raw    0.411408\n",
      "smart_7_raw      0.405340\n",
      "Name: get_percent, dtype: float64\n",
      "['smart_193_raw', 'smart_197_raw', 'smart_198_raw', 'smart_194_raw', 'smart_7_raw', 'smart_190_raw', 'smart_190_normalized', 'smart_194_normalized', 'smart_187_raw', 'smart_187_normalized', 'smart_242_raw', 'smart_240_raw', 'smart_193_normalized', 'smart_7_normalized', 'smart_1_normalized', 'smart_241_raw', 'smart_1_raw', 'smart_3_normalized', 'smart_5_raw', 'smart_192_raw', 'smart_189_raw', 'smart_189_normalized', 'smart_5_normalized', 'smart_197_normalized', 'smart_198_normalized', 'smart_188_raw', 'smart_183_raw', 'smart_183_normalized', 'smart_184_raw', 'smart_184_normalized', 'smart_199_raw']\n"
     ]
    }
   ],
   "source": [
    "selected_features = summarize.loc['get_percent'].T.sort_values(ascending=False)\n",
    "selected_features = selected_features[selected_features>0.01]\n",
    "selected_features.to_csv('./preprocess/' + model_name + '_selected_features.csv')\n",
    "print(selected_features.head())\n",
    "selected_features = selected_features.index\n",
    "irrelevent_features = ['smart_9_raw', 'smart_9_normalized', 'smart_4_raw', 'smart_4_normalized', 'smart_12_raw', 'smart_12_normalized']\n",
    "selected_features = [i for i in selected_features if i not in irrelevent_features]\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['smart_3_normalized', 'smart_192_raw', 'smart_183_raw', 'smart_183_normalized', 'smart_199_raw']\n"
     ]
    }
   ],
   "source": [
    "Sgt_features = ['serial_number', 'date', 'smart_1_normalized', 'smart_1_raw', 'smart_5_normalized', 'smart_5_raw', 'smart_7_normalized', 'smart_7_raw',\n",
    "    'smart_184_normalized', 'smart_184_raw', 'smart_187_normalized', 'smart_187_raw', 'smart_188_raw', 'smart_189_normalized', 'smart_189_raw', \n",
    "    'smart_190_normalized', 'smart_190_raw', 'smart_193_normalized', 'smart_193_raw', 'smart_194_normalized', 'smart_194_raw', 'smart_197_normalized', \n",
    "    'smart_197_raw', 'smart_198_normalized', 'smart_198_raw', 'smart_240_raw', 'smart_241_raw', 'smart_242_raw', 'failure']\n",
    "# new_features = [i for i in selected_features if i not in Sgt_features]\n",
    "new_features = [i for i in selected_features if i not in Sgt_features]\n",
    "print(new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ray\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: pd.ewm_mean is deprecated for ndarrays and will be removed in a future version\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# compact info.\n",
    "def get_cmpt_info(data):\n",
    "    return pd.ewma(data.values, span=np.round(summarize.loc['get_median', data.name]))[-1]\n",
    "functions_group1 = {n: get_cmpt_info for n in selected_features}\n",
    "# print(functions_group1)\n",
    "compacted_info = SgtA.groupby('serial_number', as_index=False).agg(functions_group1)\n",
    "compacted_info['failure'] = compacted_info.apply(lambda row: 1 if row['serial_number'] in fail_names else 0, axis=1)\n",
    "# print(compacted_info)\n",
    "compacted_info.to_csv('./preprocess/' + model_name + '_compacted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans\n",
    "# prepare set\n",
    "compacted_info = pd.read_csv('./preprocess/' + model_name + '_compacted.csv').iloc[:, 1:]\n",
    "compacted_info = compacted_info.dropna(how='any')\n",
    "fail_names = compacted_info.loc[compacted_info['failure'] == 1]['serial_number'].unique()\n",
    "n_clusters = fail_names.size // 5\n",
    "X_health = compacted_info.loc[compacted_info['failure'] == 1].drop(['serial_number', 'failure'], axis=1).values\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_jobs=-1).fit(X_health)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_health_transformed = []\n",
    "for j in range(0, n_clusters):\n",
    "    d = kmeans.transform(X_health)[:, j]\n",
    "    ind = np.argsort(d)[::-1][:10]\n",
    "    X_health_transformed[0:0] = list(X_health[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(454, 24)\n",
      "(454,)\n"
     ]
    }
   ],
   "source": [
    "X_failed = list(compacted_info.loc[compacted_info['failure'] == 1].drop(['serial_number', 'failure'], axis=1).values)\n",
    "X = np.array(X_health_transformed + X_failed)\n",
    "y = np.concatenate((np.zeros(len(X_health_transformed)), np.ones(len(X_failed))), axis=0) \n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F</th>\n",
       "      <th>Sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GBDT</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RGF</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        P    R    F   Sd\n",
       "GBDT  NaN  NaN  NaN  NaN\n",
       "SVM   NaN  NaN  NaN  NaN\n",
       "DT    NaN  NaN  NaN  NaN\n",
       "LR    NaN  NaN  NaN  NaN\n",
       "RF    NaN  NaN  NaN  NaN\n",
       "RGF   NaN  NaN  NaN  NaN"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_stat(model, X, y):\n",
    "    f_score = cross_val_score(model, X, y, cv=5, scoring='f1', n_jobs=-1)\n",
    "    r_score = cross_val_score(model, X, y, cv=5, scoring='recall', n_jobs=-1)\n",
    "    p_score = cross_val_score(model, X, y, cv=5, scoring='precision', n_jobs=-1)\n",
    "    return pd.Series({'P': np.mean(p_score), 'R': np.mean(r_score), 'F': np.mean(f_score), 'Sd': np.std(f_score)})\n",
    "\n",
    "statics = pd.DataFrame(index=['GBDT', 'SVM', 'DT', 'LR', 'RF', 'RGF'], columns=['P', 'R', 'F', 'Sd'])\n",
    "statics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    5.6s finished\n",
      "C:\\Users\\Ray\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:461: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\Ray\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:312: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\Ray\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7654772029832607\n",
      "{'C': 0.1, 'class_weight': 'balanced', 'solver': 'newton-cg'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "P      0.709357\n",
       "R      0.851183\n",
       "F       0.76521\n",
       "Sd    0.0766611\n",
       "Name: LR, dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_grid = {\n",
    "    'C': np.linspace(0.1, 0.5, 10),\n",
    "    'class_weight': ['balanced'],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "    }\n",
    "\n",
    "lr_model = LogisticRegression()\n",
    "lr_grid = GridSearchCV(estimator=lr_model, param_grid=search_grid, \n",
    "    cv=5, scoring='f1', n_jobs=-1, verbose=2)\n",
    "\n",
    "lr_grid.fit(X, y)\n",
    "print(lr_grid.best_score_)\n",
    "print(lr_grid.best_params_)\n",
    "\n",
    "statics.loc['LR'] = model_stat(lr_grid.best_estimator_, X, y)\n",
    "statics.loc['LR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    1.2s remaining:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9111214310908181\n",
      "{'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 18, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0, 'n_estimators': 13, 'random_state': 0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "P      0.986207\n",
       "R      0.850968\n",
       "F      0.911131\n",
       "Sd    0.0436708\n",
       "Name: RF, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tune RF\n",
    "n_estimators = [13] # tuned\n",
    "max_features = ['auto'] # tuned\n",
    "criterion = ['entropy']  # tuned\n",
    "max_depth = [18] # tuned\n",
    "min_samples_split = [2]\n",
    "min_samples_leaf = [1]\n",
    "min_weight_fraction_leaf = [0]\n",
    "max_leaf_nodes = [None]\n",
    "\n",
    "bootstrap = [False]\n",
    "random_state = [0]\n",
    "class_weight = ['balanced']\n",
    "search_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'criterion': criterion,\n",
    "    'max_features': max_features,\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "    'min_weight_fraction_leaf': min_weight_fraction_leaf,\n",
    "    'max_leaf_nodes': max_leaf_nodes,\n",
    "    'bootstrap': bootstrap,\n",
    "    'random_state': random_state,\n",
    "    'class_weight': class_weight\n",
    "    }\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_grid = GridSearchCV(estimator=rf_model, param_grid=search_grid, \n",
    "    cv=5, scoring='f1', n_jobs=-1, verbose=2)\n",
    "\n",
    "rf_grid.fit(X, y)\n",
    "print(rf_grid.best_score_)\n",
    "print(rf_grid.best_params_)\n",
    "\n",
    "statics.loc['RF'] = model_stat(rf_grid.best_estimator_, X, y)\n",
    "statics.loc['RF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    1.3s remaining:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8879203479050414\n",
      "{'C': 1.05, 'class_weight': 'balanced', 'gamma': 0.05, 'kernel': 'rbf', 'max_iter': -1, 'random_state': 0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "P      0.927273\n",
       "R      0.870538\n",
       "F      0.887632\n",
       "Sd    0.0740392\n",
       "Name: SVM, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tune SVM\n",
    "search_grid = {\n",
    "    'C': [1.05], \n",
    "    'kernel': ['rbf'],\n",
    "    'gamma': [0.05],\n",
    "    'class_weight': ['balanced'],\n",
    "    'max_iter': [-1],\n",
    "    'random_state': [0]\n",
    "}\n",
    "svm_model = SVC()\n",
    "svm_grid = GridSearchCV(estimator=svm_model, param_grid=search_grid, \n",
    "    cv=5, scoring='f1', n_jobs=-1, verbose=2)\n",
    "svm_grid.fit(X, y)\n",
    "\n",
    "print(svm_grid.best_score_)\n",
    "print(svm_grid.best_params_)\n",
    "statics.loc['SVM'] = model_stat(svm_grid.best_estimator_, X, y)\n",
    "statics.loc['SVM']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    1.4s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9151562729009901\n",
      "{'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 169, 'random_state': 0, 'subsample': 0.93}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "P      0.986207\n",
       "R      0.857419\n",
       "F      0.915156\n",
       "Sd    0.0407769\n",
       "Name: GBDT, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tune GBDT\n",
    "search_grid = {\n",
    "    'n_estimators': [169],\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [2],\n",
    "    'max_depth': [8],\n",
    "    'max_features':['sqrt'],\n",
    "    'subsample': [0.93],\n",
    "    'random_state': [0]\n",
    "}\n",
    "gbdt_model = GradientBoostingClassifier()\n",
    "gbdt_grid = GridSearchCV(estimator= gbdt_model, param_grid=search_grid, \n",
    "    cv=5, scoring='f1', n_jobs=-1, verbose=2)\n",
    "gbdt_grid.fit(X, y)\n",
    "\n",
    "print(gbdt_grid.best_score_)\n",
    "print(gbdt_grid.best_params_)\n",
    "\n",
    "statics.loc['GBDT'] = model_stat(gbdt_grid.best_estimator_, X, y)\n",
    "statics.loc['GBDT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   3 out of   5 | elapsed:    1.1s remaining:    0.7s\n",
      "[Parallel(n_jobs=3)]: Done   5 out of   5 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8554510846884993\n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 15, 'min_samples_split': 2, 'random_state': 0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "P       0.88536\n",
       "R      0.857849\n",
       "F      0.855107\n",
       "Sd    0.0935921\n",
       "Name: DT, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tune DT (TBI)\n",
    "search_grid = {\n",
    "    'criterion': ['entropy'],\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [15],\n",
    "    'max_depth': [8],\n",
    "    'max_features':['sqrt'],\n",
    "    'class_weight': ['balanced'],\n",
    "    'random_state': [0]\n",
    "}\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_grid = GridSearchCV(estimator= dt_model, param_grid=search_grid, \n",
    "    cv=5, scoring='f1', n_jobs=3, verbose=2)\n",
    "dt_grid.fit(X, y)\n",
    "print(dt_grid.best_score_)\n",
    "print(dt_grid.best_params_)\n",
    "\n",
    "statics.loc['DT'] = model_stat(dt_grid.best_estimator_, X, y)\n",
    "statics.loc['DT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   3 out of   5 | elapsed:    2.4s remaining:    1.6s\n",
      "[Parallel(n_jobs=3)]: Done   5 out of   5 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9111214310908181\n",
      "{'algorithm': 'RGF_Sib', 'loss': 'Log', 'max_leaf': 2000, 'test_interval': 50}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "P      0.986207\n",
       "R      0.850968\n",
       "F      0.911131\n",
       "Sd    0.0436708\n",
       "Name: RGF, dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tune RGF\n",
    "search_grid = {\n",
    "    'max_leaf': [2000],\n",
    "    'algorithm': ['RGF_Sib'],\n",
    "    'test_interval': [50],\n",
    "    'loss': ['Log']\n",
    "}\n",
    "# loss: You can select \"LS\", \"Log\", \"Expo\" or \"Abs\".\n",
    "rgf_model = RGFClassifier()\n",
    "# rgf_model = FastRGFClassifier()\n",
    "rgf_grid = GridSearchCV(estimator= rgf_model, param_grid=search_grid, \n",
    "    cv=5, scoring='f1', n_jobs=3, verbose=2)\n",
    "rgf_grid.fit(X, y)\n",
    "print(rgf_grid.best_score_)\n",
    "print(rgf_grid.best_params_)\n",
    "\n",
    "statics.loc['RGF'] = model_stat(rgf_grid.best_estimator_, X, y)\n",
    "statics.loc['RGF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GBDT</th>\n",
       "      <th>SVM</th>\n",
       "      <th>DT</th>\n",
       "      <th>LR</th>\n",
       "      <th>RF</th>\n",
       "      <th>RGF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>0.986207</td>\n",
       "      <td>0.927273</td>\n",
       "      <td>0.88536</td>\n",
       "      <td>0.709357</td>\n",
       "      <td>0.986207</td>\n",
       "      <td>0.986207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>0.857419</td>\n",
       "      <td>0.870538</td>\n",
       "      <td>0.857849</td>\n",
       "      <td>0.851183</td>\n",
       "      <td>0.850968</td>\n",
       "      <td>0.850968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>0.915156</td>\n",
       "      <td>0.887632</td>\n",
       "      <td>0.855107</td>\n",
       "      <td>0.76521</td>\n",
       "      <td>0.911131</td>\n",
       "      <td>0.911131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sd</th>\n",
       "      <td>0.0407769</td>\n",
       "      <td>0.0740392</td>\n",
       "      <td>0.0935921</td>\n",
       "      <td>0.0766611</td>\n",
       "      <td>0.0436708</td>\n",
       "      <td>0.0436708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         GBDT        SVM         DT         LR         RF        RGF\n",
       "P    0.986207   0.927273    0.88536   0.709357   0.986207   0.986207\n",
       "R    0.857419   0.870538   0.857849   0.851183   0.850968   0.850968\n",
       "F    0.915156   0.887632   0.855107    0.76521   0.911131   0.911131\n",
       "Sd  0.0407769  0.0740392  0.0935921  0.0766611  0.0436708  0.0436708"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statics.T.to_csv('./preprocess/' + model_name +'_finalstatics.csv')\n",
    "statics.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
