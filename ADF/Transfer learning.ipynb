{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from importlib import reload\n",
    "import find_cpt\n",
    "from rgf.sklearn import RGFClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold, cross_val_score, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "data_dir = \"./data-2015\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_stat(model, X, y):\n",
    "    f_score = np.average(cross_val_score(model, X, y, cv=5, scoring='f1', n_jobs=-1))\n",
    "    r_score = np.average(cross_val_score(model, X, y, cv=5, scoring='recall', n_jobs=-1))\n",
    "    p_score = np.average(cross_val_score(model, X, y, cv=5, scoring='precision', n_jobs=-1))\n",
    "    print('f1 score:' + str(f_score))\n",
    "    print('recall: ' + str(r_score))\n",
    "    print('precision: ' + str(p_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(366831, 49)\n",
      "109\n",
      "0.06438275251033668\n"
     ]
    }
   ],
   "source": [
    "# Transfer learning!\n",
    "test = pd.read_csv('./data-2015/2015-01-01.csv')\n",
    "SgtB_features = list(test.loc[test['model'] == 'ST31500541AS'].dropna(axis=1, how='all').columns.values)\n",
    "def process_SgtB(df, name):\n",
    "    df = df.loc[df['model'] == name]\n",
    "    return df[SgtB_features]\n",
    "type_dict = {feature: np.float32 for feature in SgtB_features[5:]}\n",
    "SgtB = pd.concat([process_SgtB(pd.read_csv(os.path.join('./data-2015/', filename), dtype=type_dict), 'ST31500541AS') for filename in os.listdir(data_dir)])\n",
    "print(SgtB.shape)\n",
    "\n",
    "# get fail name in B\n",
    "fail_names_SgtB = SgtB.loc[SgtB['failure'] == 1]['serial_number'].unique()\n",
    "print(fail_names_SgtB.size)\n",
    "print(fail_names_SgtB.size / SgtB['serial_number'].unique().size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "# prepare features\n",
    "test = pd.read_csv('./data-2015/2015-01-01.csv')\n",
    "SgtB_features = list(test.loc[test['model'] == 'ST31500541AS'].dropna(axis=1, how='all').columns.values)\n",
    "summarize = pd.read_csv('./preprocess/summarize.csv')\n",
    "features_percent = summarize.T[0].iloc[1:]\n",
    "selected_features = features_percent[features_percent > 0.01].sort_values(ascending=False)\n",
    "# print(selected_features)\n",
    "# irrelevent_features = ['smart_9_raw', 'smart_9_normalized', 'smart_4_raw', 'smart_4_normalized', 'smart_12_raw', 'smart_12_normalized']\n",
    "# TR_selected_features = [i for i in selected_features.index.values if i in SgtB_features and i not in irrelevent_features]\n",
    "TR_selected_features = [i for i in selected_features.index.values if i in SgtB_features]\n",
    "print(len(TR_selected_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ray\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:2540: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29670, 34)\n"
     ]
    }
   ],
   "source": [
    "compacted_info_SgtA = pd.read_csv('./preprocess/compacted.csv')\n",
    "fail_names_SgtA = compacted_info_SgtA.loc[compacted_info_SgtA['failure'] == 1]['serial_number'].unique()\n",
    "compacted_SgtA = compacted_info_SgtA[TR_selected_features]\n",
    "compacted_SgtA[['serial_number', 'failure']] = compacted_info_SgtA[['serial_number', 'failure']]\n",
    "compacted_SgtA.to_csv('./preprocess/TR_compacted_SgtA.csv')\n",
    "print(compacted_SgtA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ray\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: pd.ewm_mean is deprecated for ndarrays and will be removed in a future version\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1693, 34)\n"
     ]
    }
   ],
   "source": [
    "# Compact info\n",
    "def get_cmpt_info_SgtB(data):\n",
    "    return pd.ewma(data.values, span=np.round(summarize.iloc[1][data.name]))[-1]\n",
    "functions_group2 = {n: get_cmpt_info_SgtB for n in TR_selected_features}\n",
    "# print(functions_group1)\n",
    "compacted_SgtB = SgtB.groupby('serial_number', as_index=False).agg(functions_group2)\n",
    "compacted_SgtB['failure'] = compacted_SgtB.apply(lambda row: 1 if row['serial_number'] in fail_names_SgtB else 0, axis=1)\n",
    "compacted_SgtB.to_csv('./preprocess/TR_compacted_SgtB.csv')\n",
    "print(compacted_SgtB.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "compacted_SgtA = pd.read_csv('./preprocess/TR_compacted_SgtA.csv').drop(['Unnamed: 0'], axis=1)\n",
    "compacted_SgtB = pd.read_csv('./preprocess/TR_compacted_SgtB.csv').drop(['Unnamed: 0'], axis=1)\n",
    "compacted_SgtA = compacted_SgtA[TR_selected_features + ['serial_number', 'failure']]\n",
    "compacted_SgtB = compacted_SgtB[TR_selected_features + ['serial_number', 'failure']]\n",
    "\n",
    "fail_names_SgtA = compacted_SgtA.loc[compacted_SgtA['failure'] == 1]['serial_number'].unique()\n",
    "fail_names_SgtB = compacted_SgtB.loc[compacted_SgtB['failure'] == 1]['serial_number'].unique()\n",
    "\n",
    "# TR_selected_features = compacted_SgtB.columns.drop(['serial_number', 'failure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "TR_selected_features =['smart_1_normalized',\n",
    " 'smart_1_raw',\n",
    " 'smart_3_normalized',\n",
    " 'smart_4_raw',\n",
    " 'smart_5_raw',\n",
    " 'smart_7_normalized',\n",
    " 'smart_7_raw',\n",
    " 'smart_9_normalized',\n",
    " 'smart_9_raw',\n",
    " 'smart_12_raw',\n",
    " 'smart_183_normalized',\n",
    " 'smart_183_raw',\n",
    " 'smart_187_normalized',\n",
    " 'smart_187_raw',\n",
    " 'smart_190_normalized',\n",
    " 'smart_190_raw',\n",
    " 'smart_194_normalized',\n",
    " 'smart_194_raw',\n",
    " 'smart_197_raw',\n",
    " 'smart_198_raw',\n",
    " 'smart_240_raw',\n",
    " 'smart_241_raw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1693, 24)\n",
      "(29670, 24)\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "print(compacted_SgtB.shape)\n",
    "print(compacted_SgtA.shape)\n",
    "print(len(TR_selected_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare model\n",
    "TR_X_health = compacted_SgtA.loc[~compacted_SgtA['serial_number'].isin(fail_names_SgtA)].drop(['serial_number', 'failure'], axis=1).values\n",
    "kmeans = KMeans(n_clusters=150, random_state=0, n_jobs=-1).fit(TR_X_health)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1586, 22)\n",
      "(1586,)\n"
     ]
    }
   ],
   "source": [
    "TR_X_health_transformed = np.concatenate([TR_X_health[np.argsort(kmeans.transform(TR_X_health)[:, j])[::-1][:10]] for j in range(0, 100)], axis=0)\n",
    "TR_X_failed = compacted_SgtA.loc[compacted_SgtA['serial_number'].isin(fail_names_SgtA)].drop(['serial_number', 'failure'], axis=1).values\n",
    "TR_X_train = np.concatenate((TR_X_health_transformed, TR_X_failed), axis=0)\n",
    "TR_y_train = np.concatenate((np.zeros(TR_X_health_transformed.shape[0]), np.ones(TR_X_failed.shape[0])), axis=0) \n",
    "print(TR_X_train.shape)\n",
    "print(TR_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(586, 22)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TR_X_failed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    2.3s remaining:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score:0.9948348265944833\n",
      "recall: 0.9897725626539187\n",
      "precision: 1.0\n"
     ]
    }
   ],
   "source": [
    "# tune RGF\n",
    "search_grid = {\n",
    "    'max_leaf': [1000],\n",
    "    'algorithm': ['RGF_Sib'],\n",
    "    'test_interval': [100],\n",
    "    'loss': ['Log']\n",
    "}\n",
    "\n",
    "TR_rgf_model = RGFClassifier()\n",
    "TR_rgf_grid = GridSearchCV(estimator= TR_rgf_model, param_grid=search_grid, \n",
    "    cv=5, scoring='f1', n_jobs=-1, verbose=2)\n",
    "TR_rgf_grid.fit(TR_X_train, TR_y_train)\n",
    "model_stat(TR_rgf_model, TR_X_train, TR_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1693, 22)\n",
      "(1693,)\n",
      "109\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "TR_X_test = compacted_SgtB.drop(['serial_number', 'failure'], axis=1).values\n",
    "TR_y_test = np.array([1 if sn in fail_names_SgtB else 0 for sn in compacted_SgtB['serial_number'].values])\n",
    "print(TR_X_test.shape)\n",
    "print(TR_y_test.shape)\n",
    "print(np.sum(TR_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.11678004535147393\n",
      "recall: 0.944954128440367\n",
      "precision: 0.062235649546827795\n"
     ]
    }
   ],
   "source": [
    "TR_rgf_model = RGFClassifier(max_leaf=1000, algorithm='RGF_Sib', test_interval=100, loss='Log')\n",
    "TR_rgf_model.fit(TR_X_train, TR_y_train)\n",
    "TR_y_pred = TR_rgf_model.predict(TR_X_test)\n",
    "print('f1: ' + str(f1_score(TR_y_test, TR_y_pred)))\n",
    "print('recall: ' + str(recall_score(TR_y_test, TR_y_pred)))\n",
    "print('precision: ' + str(precision_score(TR_y_test, TR_y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    1.4s remaining:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score:0.99915611814346\n",
      "recall: 1.0\n",
      "precision: 0.9983193277310924\n",
      "{'C': 1.05, 'class_weight': 'balanced', 'gamma': 0.05, 'kernel': 'rbf', 'max_iter': -1, 'random_state': 0}\n"
     ]
    }
   ],
   "source": [
    "# tune SVM\n",
    "search_grid = {\n",
    "    'C': [1.05], \n",
    "    'kernel': ['rbf'],\n",
    "    'gamma': [0.05],\n",
    "    'class_weight': ['balanced'],\n",
    "    'max_iter': [-1],\n",
    "    'random_state': [0]\n",
    "}\n",
    "svm_model = SVC()\n",
    "svm_grid = GridSearchCV(estimator=svm_model, param_grid=search_grid, \n",
    "    cv=5, scoring='f1', n_jobs=-1, verbose=2)\n",
    "svm_grid.fit(TR_X_train, TR_y_train)\n",
    "model_stat(svm_model, TR_X_train, TR_y_train)\n",
    "print(svm_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.12097669256381798\n",
      "recall: 1.0\n",
      "precision: 0.06438275251033668\n"
     ]
    }
   ],
   "source": [
    "TR_svm_model = svm_model = SVC(C=1.05, class_weight='balanced', gamma=0.05, max_iter=-1, random_state=0)\n",
    "TR_svm_model.fit(TR_X_train, TR_y_train)\n",
    "TR_y_pred = TR_svm_model.predict(TR_X_test)\n",
    "print('f1: ' + str(f1_score(TR_y_test, TR_y_pred)))\n",
    "print('recall: ' + str(recall_score(TR_y_test, TR_y_pred)))\n",
    "print('precision: ' + str(precision_score(TR_y_test, TR_y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30777, 22)\n",
      "(30777,)\n"
     ]
    }
   ],
   "source": [
    "# do transfer learning\n",
    "TR_X_health = compacted_SgtA.loc[~compacted_SgtA['serial_number'].isin(fail_names_SgtA)].drop(['serial_number', 'failure'], axis=1).values\n",
    "\n",
    "X_all = np.concatenate([TR_X_health, TR_X_test], axis=0)\n",
    "y_all = np.concatenate([np.zeros(TR_X_health.shape[0]), np.ones(TR_X_test.shape[0])], axis=0)\n",
    "print(X_all.shape)\n",
    "print(y_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TR_svm_model = SVC(probability=True)\n",
    "model_stat(TR_svm_model, X_all, y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TR_svm_model.fit(X_all, y_all)\n",
    "prob = TR_svm_model.predict_proba(TR_X_health_transformed)[:, 1]\n",
    "print(prob)\n",
    "# X_train = TR_X_train[np.argsort(prob)[:500]]\n",
    "# y_train = TR_y_train[np.argsort(prob)[:500]]\n",
    "# sum(y_train)\n",
    "# TR_X_health_transformed = np.concatenate([TR_X_health[np.argsort(kmeans.transform(TR_X_health)[:, j])[::-1][:10]] for j in range(0, 100)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
